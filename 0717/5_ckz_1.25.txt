0 1.0
1 0.9979042717394668
2 0.9979042717394668
3 0.9996317825515653
4 0.9979042717394668
5 0.9996316654340192
6 0.9996317083960454
7 0.9997571066433446
8 0.9979042717394668
9 0.999631728802895
10 0.9996317227097377
11 0.9997558934969788
12 0.9996317619838702
13 0.9997560090019766
14 0.999756516570648
15 0.9996975109311063
16 0.9979042717394667
17 0.9996317297452706
18 0.9996317283400019
19 0.9997520860695761
20 0.9996316030672088
21 0.9997525296344386
22 0.9997534912555341
23 0.999691193125686
24 0.9996317053970816
25 0.9997536952672891
26 0.999754635298063
27 0.9996924077416258
28 0.9997553933531865
29 0.9996930752603169
30 0.9996946573002198
31 0.9990200925827147
32 0.995756254497276
lambda is 0.1800795429783899, F=0.9953822324621768

Optimizing ARP for b =  200.0
Delta_b =  1.25
Final Fidelity: 0.999291849792576
