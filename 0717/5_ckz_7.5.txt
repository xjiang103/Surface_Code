0 1.0
1 0.9995935629453668
2 0.9995935629453668
3 0.9996148296246676
4 0.9995935629453668
5 0.9996149231240219
6 0.9996151600983078
7 0.9991242990809089
8 0.9995935629453668
9 0.9996152082109375
10 0.9996164957867378
11 0.9991006126485892
12 0.9996161331064897
13 0.999097919127709
14 0.9991110571276087
15 0.9982525010510008
16 0.999593562945367
17 0.9996170584803661
18 0.9996174795952496
19 0.999006971987493
20 0.9996189983706304
21 0.9990008265911355
22 0.9990214278274079
23 0.9980653714708241
24 0.9996186856828859
25 0.9990150686843023
26 0.9990451097051
27 0.9980737862265681
28 0.9990682245409854
29 0.9980835460780068
30 0.9981245043838309
31 0.9994737571920459
32 0.9904663037079783
lambda is 0.27183875446934413, F=0.9902189478403443

Optimizing ARP for b =  200.0
Delta_b =  7.5
Final Fidelity: 0.998947396189049
9
