0 1.0
1 0.9995935629453668
2 0.9995935629453668
3 0.9996156182530664
4 0.9995935629453668
5 0.9996155613153176
6 0.9996164957867376
7 0.9991293499860476
8 0.9995935629453668
9 0.9996161379168107
10 0.9996162978782404
11 0.9991260156886235
12 0.9996161331064897
13 0.9991267789736032
14 0.9991304492147072
15 0.998302749602105
16 0.999593562945367
17 0.9996163271366868
18 0.9996170822732365
19 0.999114547831879
20 0.9996170584803661
21 0.999116159770557
22 0.9991185995218194
23 0.9982816937380732
24 0.9996169725246655
25 0.9991201270225963
26 0.9991243774788116
27 0.9982846694890487
28 0.9991252375191588
29 0.9982866228614159
30 0.9982931149777226
31 0.9997378252064827
32 0.992552740972512
lambda is 0.23879214945439386, F=0.9922331715813086

Optimizing ARP for b =  200.0
Delta_b =  2.5
Final Fidelity: 0.9990637139167763

