0 1.0
1 0.9995935629453668
2 0.9995935629453668
3 0.9996161331064898
4 0.9995935629453668
5 0.9996161331064899
6 0.9996161331064899
7 0.9991308723768499
8 0.9995935629453668
9 0.9996161331064898
10 0.9996161331064901
11 0.9991308723768497
12 0.9996161331064897
13 0.9991308723768497
14 0.9991308723768494
15 0.9983106330727227
16 0.999593562945367
17 0.9996161331064899
18 0.9996161331064898
19 0.9991308723768495
20 0.9996161331064899
21 0.9991308723768497
22 0.9991308723768499
23 0.998310633072723
24 0.9996161331064901
25 0.9991308723768497
26 0.9991308723768499
27 0.9983106330727233
28 0.9991308723768497
29 0.9983106330727229
30 0.9983106330727228
31 0.9997709935904062
32 0.9929569275002488
lambda is 0.2304253193921434, F=0.9926211445574633

Optimizing ARP for b =  200.0
Delta_b =  0.0
Final Fidelity: 0.9990823926065001
