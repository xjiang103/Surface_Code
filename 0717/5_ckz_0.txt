0 1.0
1 0.9979042717394668
2 0.9979042717394668
3 0.9996317619838703
4 0.9979042717394668
5 0.9996317619838703
6 0.9996317619838705
7 0.9997572289041743
8 0.9979042717394668
9 0.9996317619838703
10 0.99963176198387
11 0.999757228904174
12 0.9996317619838702
13 0.999757228904174
14 0.999757228904174
15 0.9997006370628354
16 0.9979042717394667
17 0.9996317619838703
18 0.99963176198387
19 0.9997572289041738
20 0.9996317619838703
21 0.9997572289041741
22 0.9997572289041741
23 0.9997006370628359
24 0.99963176198387
25 0.9997572289041738
26 0.9997572289041738
27 0.9997006370628354
28 0.9997572289041738
29 0.9997006370628354
30 0.9997006370628354
31 0.9990303000168184
32 0.9958128548247194
lambda is 0.17864764870345284, F=0.9954379345528093

Optimizing ARP for b =  200.0
Delta_b =  0.0
Final Fidelity: 0.9992956850828328
65001
